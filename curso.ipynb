{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc2eef8b",
   "metadata": {},
   "source": [
    "# S1 Introdução\n",
    "## Apache Airflow\n",
    "- Open Source - Criado pelo Airbnb em 2015. Mantido pela fundação Apache.\n",
    "- Desenvolvido em Python\n",
    "- Extensível\n",
    "\n",
    "### É um orquestrador:\n",
    "- Airflow não processa dados, ele coordena o processamento\n",
    "- Orquestra workloads (principalmente batch)\n",
    "    - Sensores e operadores \"deferrable\" -> permite `near real time`\n",
    "- O processamento ocorre em:\n",
    "    - Sistema Operacional\n",
    "    - Banco de Dados\n",
    "    - Spark\n",
    "    - Elastic Search\n",
    "    - Etc.\n",
    "- Interfaces:\n",
    "    - Web\n",
    "    - Rest API\n",
    "    - CLI\n",
    "- **DAG: estrutura básica e principal do Airflow, é um pipeline**\n",
    "- Um pipeline é composto por tasks que são partes dele, possui características como:\n",
    "    - Precedência\n",
    "    - Parelismo\n",
    "    - Independência\n",
    "\n",
    "## Pipeline:\n",
    "- Erros\n",
    "- Log/Auditoria\n",
    "- Monitoramento/Alertas\n",
    "- Recuperação a partir de um Ponto\n",
    "- Dados Históricos/ Diferenciação\n",
    "- Alta disponibilidade\n",
    "- Distribuição de Carga\"\n",
    "\n",
    "# Como funciona o Airflow:\n",
    "- DAG é um pipeline do Airflow\n",
    "    - O que este pipeline vai fazer ?\n",
    "- Formada por Operador e Task\n",
    "- **Arquitetura**:\n",
    "    - Webserver (UI)\n",
    "    - Scheduler\n",
    "    - Executor\n",
    "    - Metadata DB\n",
    "    - Triggerer\n",
    "    - Queue\n",
    "- `DAG = Directed acyclic graph: Grafo **direcionado** acíclico` \n",
    "    - Grafo: Conjunto de Vértices e Arestas\n",
    "    - Direcionado: Possui Direção Específica\n",
    "    - Acíclico: Não Circular\n",
    "    - DAG é um script python\n",
    "    - Não precisa ter a lógica (classe externa)\n",
    "    - Um mesmo script pode ter múltiplas DAGs\n",
    "    - Uma DAG pode ter uma ou mais tasks\n",
    "    - Tasks possuem dependência\n",
    "    - Um arquivo DAG pode ter uma ou mais de duas DAGs\n",
    "\n",
    "- Operators: definição do trabalho:\n",
    "    - Definem o 'o que fazer' no pipeline\n",
    "    - Derivam de **BaseOperator**\n",
    "    - Instanciados na DAG viram **Tasks**\n",
    "- Tasks: Instância de um operador na DAG\n",
    "- Interação com outras ferramentas:\n",
    "    - AWS\n",
    "    - Databricks\n",
    "    - MySQL\n",
    "    - MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad185892",
   "metadata": {},
   "source": [
    "# S2 Preparando o ambiente:\n",
    "\n",
    "- Pré-requisitos:\n",
    "    - Instalação Docker\n",
    "    - IDE:\n",
    "        - VSCODE\n",
    "    - Instalar Airflow com Docker\n",
    "\n",
    "- Instalar Airflow com Docker\n",
    "    - 1 Crie uma pasta \"airflow\"\n",
    "    - 2 Salve os seguintes arquivos na pasta:\n",
    "        - docker-compose.yaml:\n",
    "            - `C:\\Users\\MSILV221\\classes\\Forma-o-Completa-Apache-Airflow-3.1\\material\\Instalação\\docker-compose.yaml`\n",
    "        - .env\n",
    "    - 3 Siga o procedimento no próximo vídeo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92e824b",
   "metadata": {},
   "source": [
    "# S4 Estrutura básica de uma DAG\n",
    "\n",
    "```python\n",
    "###### MÓDULOS ######\n",
    "import pendulum\n",
    "from airflow import DAG\n",
    "from airflow.operators.bash import BashOperator\n",
    "\n",
    "###### DAG ######\n",
    "# Tudo dentro do contexto da DAG use a DAG de forma automática\n",
    "# Reaproveitamento de código\n",
    "`O nome da DAG não é o nome do .py !`\n",
    "with DAG(\n",
    "    dag_id = \"meu_primeiro_dag\",\n",
    "    description = \"Minha primeira DAG no Airflow\",\n",
    "    schedule = None, # Sem agendamento\n",
    "    start_date=pendulum.datetime(2024, 1, 1, tz=\"America/Sao_Paulo\"),\n",
    "    catchup = False, # Se a DAG falhar ele executa execuções passadas que ficaram pendentes\n",
    "    tags=[\"curso\", \"exemplo\"],\n",
    ") as dag:\n",
    "###### TASKS ######\n",
    "    task1 = BashOperator(\n",
    "        task_id = \"task1\",\n",
    "        bash_command = \"sleep 5\",\n",
    "    ),\n",
    "    task2 = BashOperator(\n",
    "        task_id = \"task2\",\n",
    "        bash_command = \"echo 'Hello, Airflow!'\",\n",
    "    )\n",
    "    task3 = BashOperator(\n",
    "        task_id = \"task3\",\n",
    "        bash_command = \"date\",\n",
    "    )\n",
    "##### Ordem de precedência / Execução ######\n",
    "    task1 >> task2 >> task3 # Indica a ordem de execução\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cc73f5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55e4d990",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
