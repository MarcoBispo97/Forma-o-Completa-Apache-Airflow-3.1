{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc2eef8b",
   "metadata": {},
   "source": [
    "# S1 Introdução\n",
    "## Apache Airflow\n",
    "- Open Source - Criado pelo Airbnb em 2015. Mantido pela fundação Apache.\n",
    "- Desenvolvido em Python\n",
    "- Extensível\n",
    "\n",
    "### É um orquestrador:\n",
    "- Airflow não processa dados, ele coordena o processamento\n",
    "- Orquestra workloads (principalmente batch)\n",
    "    - Sensores e operadores \"deferrable\" -> permite `near real time`\n",
    "- O processamento ocorre em:\n",
    "    - Sistema Operacional\n",
    "    - Banco de Dados\n",
    "    - Spark\n",
    "    - Elastic Search\n",
    "    - Etc.\n",
    "- Interfaces:\n",
    "    - Web\n",
    "    - Rest API\n",
    "    - CLI\n",
    "- **DAG: estrutura básica e principal do Airflow, é um pipeline**\n",
    "- Um pipeline é composto por tasks que são partes dele, possui características como:\n",
    "    - Precedência\n",
    "    - Parelismo\n",
    "    - Independência\n",
    "\n",
    "## Pipeline:\n",
    "- Erros\n",
    "- Log/Auditoria\n",
    "- Monitoramento/Alertas\n",
    "- Recuperação a partir de um Ponto\n",
    "- Dados Históricos/ Diferenciação\n",
    "- Alta disponibilidade\n",
    "- Distribuição de Carga\"\n",
    "\n",
    "# Como funciona o Airflow:\n",
    "- DAG é um pipeline do Airflow\n",
    "    - O que este pipeline vai fazer ?\n",
    "- Formada por Operador e Task\n",
    "- **Arquitetura**:\n",
    "    - Webserver (UI)\n",
    "    - Scheduler\n",
    "    - Executor\n",
    "    - Metadata DB\n",
    "    - Triggerer\n",
    "    - Queue\n",
    "- `DAG = Directed acyclic graph: Grafo **direcionado** acíclico` \n",
    "    - Grafo: Conjunto de Vértices e Arestas\n",
    "    - Direcionado: Possui Direção Específica\n",
    "    - Acíclico: Não Circular\n",
    "    - DAG é um script python\n",
    "    - Não precisa ter a lógica (classe externa)\n",
    "    - Um mesmo script pode ter múltiplas DAGs\n",
    "    - Uma DAG pode ter uma ou mais tasks\n",
    "    - Tasks possuem dependência\n",
    "    - Um arquivo DAG pode ter uma ou mais de duas DAGs\n",
    "\n",
    "- Operators: definição do trabalho:\n",
    "    - Definem o 'o que fazer' no pipeline\n",
    "    - Derivam de **BaseOperator**\n",
    "    - Instanciados na DAG viram **Tasks**\n",
    "- Tasks: Instância de um operador na DAG\n",
    "- Interação com outras ferramentas:\n",
    "    - AWS\n",
    "    - Databricks\n",
    "    - MySQL\n",
    "    - MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad185892",
   "metadata": {},
   "source": [
    "# S2 Preparando o ambiente:\n",
    "\n",
    "- Pré-requisitos:\n",
    "    - Instalação Docker\n",
    "    - IDE:\n",
    "        - VSCODE\n",
    "    - Instalar Airflow com Docker\n",
    "\n",
    "- Instalar Airflow com Docker\n",
    "    - 1 Crie uma pasta \"airflow\"\n",
    "    - 2 Salve os seguintes arquivos na pasta:\n",
    "        - docker-compose.yaml:\n",
    "            - `C:\\Users\\MSILV221\\classes\\Forma-o-Completa-Apache-Airflow-3.1\\material\\Instalação\\docker-compose.yaml`\n",
    "        - .env\n",
    "    - 3 Siga o procedimento no próximo vídeo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cc73f5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55e4d990",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
